# üöÄ Solutions pour Acc√©l√©rer l'Entra√Ænement

## ‚ö†Ô∏è Probl√®me Actuel

**53 minutes pour 2 epochs** - C'est normal sur CPU avec ~5000 images !

---

## ‚úÖ Solution 1 : R√©duire le Dataset (RECOMMAND√â)

### Cr√©er un Petit Dataset de Test

Utilisez seulement 10% des donn√©es :

```python
# Dans train_model.py, modifier get_data_loaders()

def get_data_loaders(data_dir, batch_size=32, sample_size=0.1):
    """
    sample_size: fraction du dataset √† utiliser (0.1 = 10%)
    """
    # ... (transformations existantes)
    
    # Chargement des datasets
    train_dataset = datasets.ImageFolder(
        root=os.path.join(data_dir, 'train'),
        transform=train_transforms
    )
    
    # NOUVEAU : √âchantillonner seulement 10%
    if sample_size < 1.0:
        import random
        indices = random.sample(range(len(train_dataset)), 
                               int(len(train_dataset) * sample_size))
        train_dataset = torch.utils.data.Subset(train_dataset, indices)
    
    # Pareil pour validation et test
    val_dataset = datasets.ImageFolder(...)
    if sample_size < 1.0:
        indices = random.sample(range(len(val_dataset)), 
                               int(len(val_dataset) * sample_size))
        val_dataset = torch.utils.data.Subset(val_dataset, indices)
```

**R√©sultat** : 
- 10% des donn√©es = ~500 images
- **Dur√©e : 5-7 minutes pour 2 epochs** ‚úÖ

---

## ‚úÖ Solution 2 : Augmenter le Batch Size

```python
# Dans pipeline.py
train_model_task = PythonOperator(
    task_id='train_model',
    python_callable=train,
    op_kwargs={
        'data_dir': '/opt/airflow/dags/data/chest_xray',
        'epochs': 2,
        'batch_size': 64,  # Au lieu de 32
        'learning_rate': 0.001,
    },
    dag=dag,
)
```

**R√©sultat** : ~30% plus rapide

---

## ‚úÖ Solution 3 : Utiliser un Mod√®le Plus Petit

```python
# Dans train_model.py
def create_model(num_classes=2):
    # Au lieu de ResNet18, utiliser MobileNetV2
    model = models.mobilenet_v2(pretrained=True)
    model.classifier[1] = nn.Linear(model.last_channel, num_classes)
    return model
```

**R√©sultat** : ~50% plus rapide

---

## ‚úÖ Solution 4 : Mode "Demo Rapide"

Cr√©ez un fichier `train_model_fast.py` avec :

```python
def train_fast(data_dir='/opt/airflow/dags/data/chest_xray'):
    """Version ultra-rapide pour d√©mo"""
    
    # Seulement 100 images
    # 1 epoch
    # Batch size 64
    # MobileNetV2
    
    # Dur√©e : 2-3 minutes ‚úÖ
```

---

## üéØ MA RECOMMANDATION IMM√âDIATE

**Arr√™tez le run actuel et utilisez cette configuration** :

```python
# pipeline.py
train_model_task = PythonOperator(
    task_id='train_model',
    python_callable=train,
    op_kwargs={
        'data_dir': '/opt/airflow/dags/data/chest_xray',
        'epochs': 1,           # 1 seul epoch
        'batch_size': 64,      # Plus gros batch
        'learning_rate': 0.001,
    },
    dag=dag,
)
```

**Dur√©e estim√©e : 15-20 minutes** (au lieu de 53)

---

## üöÄ Solution Ultime : GPU

Si vous avez une carte NVIDIA :

1. Installer CUDA
2. Modifier `requirements.txt` pour PyTorch GPU
3. Ajouter `runtime: nvidia` dans docker-compose

**R√©sultat : 2-3 minutes pour 2 epochs** üöÄ

---

## ‚è±Ô∏è Comparaison des Temps

| Configuration | Temps (2 epochs) |
|---------------|------------------|
| **Actuel** (CPU, 5000 images, batch 32) | 53 min ‚ùå |
| CPU, 500 images (10%), batch 32 | 5-7 min ‚úÖ |
| CPU, 5000 images, batch 64 | 35 min ‚ö†Ô∏è |
| CPU, 1 epoch, batch 64 | 15-20 min ‚úÖ |
| GPU, 5000 images, batch 32 | 2-3 min üöÄ |

---

## üéØ POUR VOTRE PROJET MLOPS

**Vous n'avez PAS besoin d'un mod√®le parfait !**

Pour d√©montrer le pipeline MLOps :
- ‚úÖ 1 epoch suffit
- ‚úÖ 10% des donn√©es suffit
- ‚úÖ L'important c'est que le pipeline fonctionne

**Le but** : Montrer l'orchestration, pas la performance du mod√®le !

---

**Voulez-vous que je modifie le pipeline pour 1 epoch + batch 64 ?** (15-20 min au lieu de 53)
