# üöÄ GUIDE COMPLET : Projet MLOps dans GitHub Codespaces
## Continuous Retraining Pipeline - De A √† Z

---

## üìã PARTIE 1 : PR√âPARATION (Sur votre PC Windows)

### √âtape 1.1 : Cr√©er le repository GitHub

1. Allez sur https://github.com
2. Cliquez sur **"New repository"**
3. Nom : `mlops-pneumonia-detection`
4. Description : `Continuous Retraining Pipeline with Airflow, DVC, GitHub`
5. **Public** (pour que le prof puisse voir)
6. ‚úÖ Cochez **"Add a README file"**
7. Cliquez sur **"Create repository"**

### √âtape 1.2 : Pr√©parer les fichiers localement

```powershell
cd C:\Users\yassine\Desktop\PROJET_MLOPS

# Initialiser Git si pas d√©j√† fait
git init
git add .
git commit -m "Initial MLOps project setup"

# Lier au repository GitHub
git remote add origin https://github.com/VOTRE_USERNAME/mlops-pneumonia-detection.git
git branch -M main
git push -u origin main
```

**‚ö†Ô∏è IMPORTANT** : Les donn√©es (images) sont trop lourdes pour GitHub.
On va les g√©rer avec DVC dans Codespaces.

---

## üìã PARTIE 2 : CONFIGURATION CODESPACES

### √âtape 2.1 : Cr√©er le fichier de configuration Codespaces

Cr√©ez le dossier et fichier `.devcontainer/devcontainer.json` :

```json
{
  "name": "MLOps Pneumonia Detection",
  "image": "mcr.microsoft.com/devcontainers/python:3.10",
  "features": {
    "ghcr.io/devcontainers/features/docker-in-docker:2": {},
    "ghcr.io/devcontainers/features/git:1": {}
  },
  "customizations": {
    "vscode": {
      "extensions": [
        "ms-python.python",
        "ms-azuretools.vscode-docker"
      ]
    }
  },
  "forwardPorts": [8080, 5000, 8000],
  "portsAttributes": {
    "8080": {
      "label": "Airflow UI",
      "onAutoForward": "notify"
    },
    "5000": {
      "label": "MLflow UI",
      "onAutoForward": "notify"
    },
    "8000": {
      "label": "Django App",
      "onAutoForward": "notify"
    }
  },
  "postCreateCommand": "echo 'Codespace ready! Run: docker-compose up -d'"
}
```

### √âtape 2.2 : Pousser la configuration

```powershell
git add .devcontainer/
git commit -m "Add Codespaces configuration"
git push origin main
```

---

## üìã PARTIE 3 : LANCER CODESPACES

### √âtape 3.1 : Cr√©er le Codespace

1. Allez sur votre repo GitHub : `https://github.com/VOTRE_USERNAME/mlops-pneumonia-detection`
2. Cliquez sur le bouton vert **"<> Code"**
3. Onglet **"Codespaces"**
4. Cliquez sur **"Create codespace on main"**

‚è±Ô∏è **Attendez 3-5 minutes** que l'environnement se cr√©e.

### √âtape 3.2 : V√©rifier l'environnement

Dans le terminal Codespaces :

```bash
# V√©rifier Docker
docker --version
# Output attendu: Docker version 24.x.x

# V√©rifier Python
python --version
# Output attendu: Python 3.10.x

# V√©rifier la structure
ls -la
# Vous devez voir: dags/, docker-compose.yaml, requirements.txt, etc.
```

---

## üìã PARTIE 4 : INSTALLER LES D√âPENDANCES

### √âtape 4.1 : Cr√©er le fichier requirements.txt (si manquant)

```bash
cat > requirements.txt << 'EOF'
apache-airflow==2.8.0
mlflow==2.9.2
torch==2.1.2
torchvision==0.16.2
pillow==10.0.0
dvc==3.37.0
psycopg2-binary==2.9.9
EOF
```

### √âtape 4.2 : Installer les d√©pendances Python

```bash
pip install -r requirements.txt
```

---

## üìã PARTIE 5 : CONFIGURER LES DONN√âES (DVC)

### √âtape 5.1 : Initialiser DVC

```bash
# Initialiser DVC
dvc init

# Ajouter un remote (stockage local pour la d√©mo)
dvc remote add -d local /tmp/dvc-storage
mkdir -p /tmp/dvc-storage
```

### √âtape 5.2 : T√©l√©charger le dataset (version simplifi√©e)

Pour la d√©mo dans Codespaces, on va utiliser un subset du dataset :

```bash
# Cr√©er la structure
mkdir -p dags/data/chest_xray/{train,test,val}/{NORMAL,PNEUMONIA}

# T√©l√©charger quelques images de test (exemple avec wget)
# Ou uploadez manuellement quelques images via l'interface Codespaces
```

**Alternative** : Si vous avez d√©j√† le dataset en local, uploadez-le via l'interface Codespaces (glisser-d√©poser).

### √âtape 5.3 : Tracker avec DVC

```bash
# Ajouter les donn√©es √† DVC
dvc add dags/data/chest_xray

# Commit
git add dags/data/chest_xray.dvc .dvc/
git commit -m "Add dataset with DVC"
git push origin main
```

---

## üìã PARTIE 6 : LANCER L'INFRASTRUCTURE DOCKER

### √âtape 6.1 : V√©rifier docker-compose.yaml

Assurez-vous que le fichier existe et contient les 4 services :
- postgres
- mlflow
- airflow-webserver
- airflow-scheduler

### √âtape 6.2 : D√©marrer les services

```bash
# Lancer Docker Compose
docker-compose up -d

# V√©rifier que tout tourne
docker-compose ps

# Vous devez voir 4 conteneurs "Up"
```

### √âtape 6.3 : Attendre l'initialisation

```bash
# Suivre les logs
docker-compose logs -f airflow-scheduler

# Attendez de voir : "Scheduler started"
# Ctrl+C pour arr√™ter les logs
```

---

## üìã PARTIE 7 : V√âRIFIER LES DAGs AIRFLOW

### √âtape 7.1 : Acc√©der √† l'interface Airflow

1. Dans Codespaces, allez dans l'onglet **"PORTS"** (en bas)
2. Trouvez le port **8080** (Airflow UI)
3. Cliquez sur l'ic√¥ne **"Globe"** üåê pour ouvrir l'URL
4. Login : `airflow` / `airflow`

### √âtape 7.2 : V√©rifier que les DAGs apparaissent

Vous devriez voir :
- ‚úÖ `continuous_retraining_dag` (ou `continuous_retraining_simple`)
- ‚úÖ `pipeline_pneumonia_yassine`
- ‚úÖ Peut-√™tre des DAGs d'exemple

**Si les DAGs n'apparaissent pas** :

```bash
# V√©rifier que les fichiers sont bien mont√©s
docker-compose exec airflow-scheduler ls -la /opt/airflow/dags/

# Si vide, copier manuellement
docker cp dags/continuous_retraining_dag.py \
  $(docker-compose ps -q airflow-scheduler):/opt/airflow/dags/

# Red√©marrer le scheduler
docker-compose restart airflow-scheduler
```

---

## üìã PARTIE 8 : TESTER LE CONTINUOUS TRAINING

### √âtape 8.1 : Activer le DAG

1. Dans l'interface Airflow
2. Trouvez `continuous_retraining_dag`
3. Activez le toggle (bouton ON/OFF)

### √âtape 8.2 : Trigger manuel (pour la d√©mo)

1. Cliquez sur le nom du DAG
2. Cliquez sur le bouton **"Trigger DAG"** (‚ñ∂Ô∏è en haut √† droite)
3. Confirmez

### √âtape 8.3 : Suivre l'ex√©cution

1. Cliquez sur l'onglet **"Graph"**
2. Vous verrez le workflow :
   ```
   check_data ‚Üí pull_data ‚Üí train ‚Üí compare ‚Üí deploy ‚Üí notify
   ```
3. Les t√¢ches vont passer de gris ‚Üí jaune ‚Üí vert (ou rouge si erreur)

### √âtape 8.4 : Voir les logs

1. Cliquez sur une t√¢che (ex: `train_new_model`)
2. Cliquez sur **"Log"**
3. Vous verrez les d√©tails de l'ex√©cution

---

## üìã PARTIE 9 : V√âRIFIER MLFLOW

### √âtape 9.1 : Acc√©der √† MLflow

1. Dans l'onglet **"PORTS"** de Codespaces
2. Trouvez le port **5000** (MLflow UI)
3. Cliquez sur l'ic√¥ne **"Globe"** üåê

### √âtape 9.2 : Voir les exp√©riences

1. Vous devriez voir l'experiment **"pneumonia_detection"**
2. Cliquez dessus
3. Vous verrez les runs d'entra√Ænement avec :
   - Hyperparam√®tres
   - M√©triques (accuracy, loss)
   - Mod√®les sauvegard√©s

---

## üìã PARTIE 10 : PREUVES POUR LE PROF

### Option A : Partager l'URL Codespaces

1. Dans l'onglet **"PORTS"**
2. Clic droit sur le port **8080** (Airflow)
3. **"Port Visibility"** ‚Üí **"Public"**
4. Copiez l'URL
5. Envoyez au prof avec le message :

> "Professeur, voici l'URL de mon pipeline Airflow fonctionnel dans GitHub Codespaces : [URL]. Vous pouvez voir les DAGs de continuous retraining en action. Login : airflow / airflow"

### Option B : Captures d'√©cran

Prenez des screenshots de :

1. **Liste des DAGs** dans Airflow
2. **Graph View** du DAG `continuous_retraining_dag`
3. **Logs** d'une t√¢che d'entra√Ænement
4. **MLflow** montrant les runs track√©s
5. **Terminal Codespaces** montrant `docker-compose ps`

### Option C : Vid√©o de d√©monstration

Enregistrez une vid√©o (5 minutes) montrant :

1. Codespaces ouvert
2. `docker-compose ps` dans le terminal
3. Airflow UI avec les DAGs
4. Trigger d'un DAG
5. Ex√©cution en temps r√©el
6. MLflow avec les r√©sultats

---

## üìã PARTIE 11 : CONTINUOUS TRAINING EXPLIQU√â

### Comment √ßa marche dans votre projet

1. **D√©tection** : Airflow v√©rifie quotidiennement (`@daily`) si de nouvelles donn√©es sont dans DVC
2. **Pull** : Si oui, il pull les nouvelles donn√©es avec `dvc pull`
3. **Train** : Il lance `train_model.py` avec PyTorch
4. **Track** : Toutes les m√©triques sont envoy√©es √† MLflow
5. **Compare** : Il compare le nouveau mod√®le avec l'ancien (via MLflow)
6. **Deploy** : Si meilleur, il d√©ploie automatiquement (simulation dans la d√©mo)

### Code cl√© du DAG

```python
with DAG('continuous_retraining', schedule_interval='@daily') as dag:
    
    check = BranchPythonOperator(
        task_id='check_new_data',
        python_callable=check_for_updates
    )
    
    train = PythonOperator(
        task_id='train_new_model',
        python_callable=train_model_logic
    )
    
    compare = BranchPythonOperator(
        task_id='compare_models',
        python_callable=compare_performance
    )
    
    deploy = PythonOperator(
        task_id='deploy_to_production',
        python_callable=deploy_model
    )

    check >> train >> compare >> deploy
```

---

## üéØ CHECKLIST FINALE

- [ ] Repository GitHub cr√©√©
- [ ] Code push√© sur GitHub
- [ ] `.devcontainer/devcontainer.json` cr√©√©
- [ ] Codespace lanc√©
- [ ] Docker v√©rifi√© (`docker --version`)
- [ ] `docker-compose up -d` ex√©cut√©
- [ ] 4 conteneurs "Up" (`docker-compose ps`)
- [ ] Airflow accessible (port 8080)
- [ ] DAGs visibles dans Airflow UI
- [ ] DAG activ√© et trigger manuel test√©
- [ ] MLflow accessible (port 5000)
- [ ] Runs visibles dans MLflow
- [ ] Screenshots/vid√©o captur√©s
- [ ] URL partag√©e avec le prof (ou preuves envoy√©es)

---

## üí° ARGUMENTS POUR LE PROF

Quand vous lui montrez :

> "Professeur, j'ai rencontr√© des limitations techniques avec Docker sur Windows. Suivant votre conseil, j'ai migr√© vers **GitHub Codespaces**, qui est l'environnement de d√©veloppement cloud recommand√© par l'industrie. Cela d√©montre :
> 
> 1. Ma capacit√© √† **m'adapter** aux contraintes techniques
> 2. Ma ma√Ætrise des **outils modernes** (Codespaces, Docker, Airflow)
> 3. Un pipeline **reproductible** : n'importe qui peut cloner mon repo et lancer le Codespace
> 4. Une approche **professionnelle** : c'est exactement comme √ßa que les √©quipes MLOps travaillent en entreprise
> 
> Mon pipeline de **Continuous Retraining** est maintenant pleinement fonctionnel et d√©montrable."

---

## üö® D√âPANNAGE RAPIDE

### Probl√®me : DAGs ne s'affichent pas

```bash
# V√©rifier les logs du scheduler
docker-compose logs airflow-scheduler | grep ERROR

# Copier manuellement les DAGs
docker cp dags/ $(docker-compose ps -q airflow-scheduler):/opt/airflow/

# Red√©marrer
docker-compose restart airflow-scheduler
```

### Probl√®me : Out of memory

```bash
# R√©duire les ressources dans docker-compose.yaml
# Commentez les limites de m√©moire

# Ou utilisez un Codespace plus puissant (4-core)
```

### Probl√®me : Port d√©j√† utilis√©

```bash
# Arr√™ter tout
docker-compose down

# Nettoyer
docker system prune -f

# Relancer
docker-compose up -d
```

---

## ‚úÖ R√âSULTAT ATTENDU

√Ä la fin de ce guide, vous aurez :

1. ‚úÖ Un projet MLOps complet dans GitHub Codespaces
2. ‚úÖ Airflow fonctionnel avec DAGs visibles
3. ‚úÖ MLflow trackant les exp√©riences
4. ‚úÖ Un pipeline de Continuous Retraining d√©montrable
5. ‚úÖ Une URL partageable avec le prof
6. ‚úÖ Des preuves visuelles (screenshots/vid√©o)

**Temps estim√©** : 1-2 heures (en suivant ce guide pas √† pas)

---

**Bonne chance ! Vous allez r√©cup√©rer vos points ! üöÄ**
