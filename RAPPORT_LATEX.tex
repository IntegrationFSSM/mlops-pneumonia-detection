\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{tcolorbox}

\geometry{margin=2.5cm}

% Configuration des couleurs
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% Style pour le code
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

% En-tête et pied de page
\pagestyle{fancy}
\fancyhf{}
\begin{titlepage}
    \centering
    % En-tête Université
    {\Large \textsc{Université Cadi Ayyad}}\\
    {\large \textsc{Faculté des Sciences et Techniques - Marrakech}}\\[1.0cm]

    % Logo
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.35\textwidth]{logo_uca.png}
    \end{figure}
    \vspace{1.5cm}

    % Titre avec lignes (tirets)
    \rule{\linewidth}{0.5mm} \\[0.4cm]
    { \huge \bfseries Continuous Retraining Pipeline \\[0.4cm] 
      \LARGE with Airflow, DVC, GitHub \\[0.4cm] 
      \large Détection de Pneumonie sur Radiographies Thoraciques } \\[0.4cm]
    \rule{\linewidth}{0.5mm} \\[2cm]

    % Information de réalisation et supervision
    \begin{minipage}{0.45\textwidth}
        \begin{flushleft} \large
        \emph{Réalisé par :}\\
        \textbf{Yassine ENNHILI}
        \end{flushleft}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \begin{flushright} \large
        \emph{Supervisé par :}\\
        \textbf{Pr. VOTRE SUPERVISEUR} % À modifier si besoin
        \end{flushright}
    \end{minipage}

    \vfill

    % Bas de page
    {\large Année Universitaire 2024-2025}\\[1cm]
    
\end{titlepage}

\newpage
\thispagestyle{empty}
\vspace*{5cm}
\begin{center}
    \large\itshape
    À ma famille,\\
    pour leur soutien inconditionnel et leurs encouragements constants.\\
    À mes amis et collègues de promotion.
\end{center}
\vfill

\newpage
\thispagestyle{empty}
\chapter*{Remerciements}
Je tiens tout d'abord à exprimer ma profonde gratitude à mon encadrant, \textbf{Pr. VOTRE SUPERVISEUR}, pour ses précieux conseils, sa disponibilité et son orientation judicieuse tout au long de ce projet. Son expertise a été déterminante dans l'accomplissement de ce travail.

Je remercie également le corps professoral de la \textbf{Faculté des Sciences et Techniques de Marrakech} pour la qualité de l'enseignement dispensé et pour nous avoir offert un environnement propice à l'apprentissage et à l'innovation.

Enfin, mes remerciements vont à tous ceux qui, de près ou de loin, ont contribué à la réalisation de ce projet MLOps ambitieux.

\newpage
\chapter*{Résumé}
Ce projet présente la conception et la mise en œuvre d'un pipeline MLOps complet pour la détection automatisée de la pneumonie à partir d'images de radiographies thoraciques. L'architecture repose sur l'intégration de technologies de pointe : Docker pour la conteneurisation, Apache Airflow pour l'orchestration des flux de travail, DVC pour le versioning des données, et MLflow pour le suivi des expériences. L'innovation majeure réside dans l'implémentation d'un système de \textit{Continuous Retraining} (réentraînement continu) capable de mettre à jour le modèle de Deep Learning (ResNet18) de manière autonome lorsque de nouvelles données sont disponibles. L'application finale est déployée sur le cloud via Heroku, offrant une interface web réactive développée avec Django pour assister les professionnels de santé.

\textbf{Mots-clés :} MLOps, Deep Learning, Pneumonie, Airflow, Docker, Continuous Training, Heroku.

\vspace{1cm}
\hrule
\vspace{1cm}

\chapter*{Abstract}
This project presents the design and implementation of a complete MLOps pipeline for automated pneumonia detection from chest X-ray images. The architecture relies on the integration of cutting-edge technologies: Docker for containerization, Apache Airflow for workflow orchestration, DVC for data versioning, and MLflow for experiment tracking. The major innovation lies in the implementation of a \textit{Continuous Retraining} system capable of autonomously updating the Deep Learning model (ResNet18) when new data becomes available. The final application is deployed on the cloud via Heroku, providing a responsive web interface developed with Django to assist healthcare professionals.

\textbf{Keywords:} MLOps, Deep Learning, Pneumonia, Airflow, Docker, Continuous Training, Heroku.

\newpage
\chapter*{Liste des Abréviations}
\begin{center}
\begin{tabular}{l l}
    \textbf{API} & Application Programming Interface \\
    \textbf{CNN} & Convolutional Neural Network \\
    \textbf{DAG} & Directed Acyclic Graph \\
    \textbf{DVC} & Data Version Control \\
    \textbf{ML} & Machine Learning \\
    \textbf{MLOps} & Machine Learning Operations \\
    \textbf{PaaS} & Platform as a Service \\
    \textbf{UI} & User Interface \\
    \textbf{VM} & Virtual Machine \\
    \textbf{WSGI} & Web Server Gateway Interface \\
\end{tabular}
\end{center}

\newpage
\tableofcontents
\newpage

\section{Introduction}

\subsection{Contexte du Projet}

La pneumonie est une infection respiratoire aiguë qui affecte les poumons et représente l'une des principales causes de mortalité dans le monde, avec environ 2,5 millions de décès par an. Le diagnostic rapide et précis de la pneumonie est crucial pour un traitement efficace.

Ce projet vise à créer un \textbf{pipeline MLOps complet} pour automatiser la détection de pneumonie sur des radiographies thoraciques en utilisant l'intelligence artificielle et les meilleures pratiques DevOps.

\subsection{Objectifs}

\begin{itemize}
    \item Développer un modèle de deep learning performant pour la détection de pneumonie
    \item Implémenter un pipeline MLOps complet et reproductible
    \item Automatiser l'entraînement et le déploiement du modèle
    \item Créer une interface web utilisable en production
    \item Déployer l'application sur le cloud (Heroku)
\end{itemize}

\subsection{Technologies Utilisées}

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Composant} & \textbf{Technologie} & \textbf{Version} \\
\hline
Orchestration & Apache Airflow & 2.8.0 \\
Tracking & MLflow & 2.9.2 \\
Containerisation & Docker Compose & - \\
Base de données & PostgreSQL & 13 \\
ML Framework & PyTorch & 2.1.2 \\
Versioning Code & Git & - \\
Versioning Data & DVC & 3.37.0 \\
Interface Web & Django & 4.2.0 \\
Cloud & Heroku & - \\
\hline
\end{tabular}
\caption{Stack technologique du projet}
\end{table}

\newpage

\section{Architecture du Système}

\subsection{Vue d'Ensemble}

Le système est composé de plusieurs couches interconnectées :

\begin{enumerate}
    \item \textbf{Couche Données} : Versioning avec DVC
    \item \textbf{Couche Code} : Versioning avec Git
    \item \textbf{Couche Infrastructure} : Docker Compose
    \item \textbf{Couche Orchestration} : Apache Airflow
    \item \textbf{Couche ML} : PyTorch + MLflow
    \item \textbf{Couche Présentation} : Django
    \item \textbf{Couche Déploiement} : Heroku
\end{enumerate}

\subsection{Diagramme d'Architecture}

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Pipeline MLOps]
\textbf{Flux de données :}
\begin{enumerate}
    \item Dataset (DVC) $\rightarrow$ Versioning
    \item Code (Git) $\rightarrow$ Versioning
    \item Docker $\rightarrow$ Infrastructure isolée
    \item Airflow $\rightarrow$ Orchestration automatique
    \item PyTorch $\rightarrow$ Entraînement du modèle
    \item MLflow $\rightarrow$ Tracking des expériences
    \item Django $\rightarrow$ Interface web
    \item Heroku $\rightarrow$ Déploiement production
\end{enumerate}
\end{tcolorbox}

\newpage

\section{Installation et Configuration}

\subsection{Prérequis}

\begin{itemize}
    \item Docker Desktop (Windows/Mac) ou Docker Engine (Linux)
    \item Git
    \item Python 3.10+
    \item 8 GB RAM minimum
    \item 20 GB espace disque
\end{itemize}

\subsection{Clonage du Projet}

\begin{lstlisting}[language=bash]
# Cloner le repository
git clone <repository-url>
cd PROJET_MLOPS

# Initialiser DVC
dvc pull  # Télécharger les données
\end{lstlisting}

\subsection{Configuration Docker}

\textbf{Fichier docker-compose.yaml :}

\begin{lstlisting}[language=yaml]
version: '3.8'

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.2
    ports:
      - "5000:5000"
    volumes:
      - mlflow-artifacts:/mlflow
    command: >
      mlflow server
      --backend-store-uri file:///mlflow/mlruns
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000

  airflow-webserver:
    build: .
    command: webserver
    ports:
      - "8080:8080"
    depends_on:
      - postgres

  airflow-scheduler:
    build: .
    command: scheduler
    depends_on:
      - postgres
\end{lstlisting}

\subsection{Démarrage de l'Infrastructure}

\begin{lstlisting}[language=bash]
# Construire les images Docker
docker-compose build

# Démarrer tous les services
docker-compose up -d

# Vérifier l'état des services
docker-compose ps
\end{lstlisting}

\newpage

\section{Modèle de Machine Learning}

\subsection{Architecture du Modèle}

Le modèle utilise \textbf{ResNet18}, une architecture de réseau de neurones convolutifs (CNN) pré-entraînée sur ImageNet, avec la technique de \textbf{Transfer Learning}.

\subsubsection{Caractéristiques}

\begin{itemize}
    \item \textbf{Architecture} : ResNet18 (18 couches)
    \item \textbf{Input} : Images 224×224 pixels
    \item \textbf{Output} : 2 classes (NORMAL, PNEUMONIA)
    \item \textbf{Optimizer} : Adam
    \item \textbf{Learning Rate} : 0.001
    \item \textbf{Batch Size} : 64
    \item \textbf{Epochs} : 10-20 (production), 1 (démo)
\end{itemize}

\subsection{Dataset}

\textbf{Source} : Chest X-Ray Images (Pneumonia) - Kaggle

\begin{table}[h]
\centering
\begin{tabular}{|l|r|}
\hline
\textbf{Métrique} & \textbf{Valeur} \\
\hline
Total d'images & 5,863 \\
Images NORMAL & 1,583 \\
Images PNEUMONIA & 4,280 \\
Train set & 5,216 (89\%) \\
Validation set & 16 (0.3\%) \\
Test set & 631 (11\%) \\
\hline
\end{tabular}
\caption{Distribution du dataset}
\end{table}

\subsection{Code d'Entraînement}

\begin{lstlisting}[language=Python]
import torch
import torch.nn as nn
from torchvision import models, transforms
import mlflow

def train(data_dir, epochs=10, batch_size=64, learning_rate=0.001):
    # Configuration MLflow
    mlflow.set_tracking_uri("http://mlflow:5000")
    mlflow.set_experiment("pneumonia_detection")
    
    with mlflow.start_run():
        # Log des hyperparamètres
        mlflow.log_param("epochs", epochs)
        mlflow.log_param("batch_size", batch_size)
        mlflow.log_param("learning_rate", learning_rate)
        
        # Chargement du modèle ResNet18
        model = models.resnet18(pretrained=True)
        model.fc = nn.Linear(model.fc.in_features, 2)
        
        # Entraînement
        for epoch in range(epochs):
            # ... code d'entraînement ...
            
            # Log des métriques
            mlflow.log_metric("train_loss", train_loss, step=epoch)
            mlflow.log_metric("train_accuracy", train_acc, step=epoch)
        
        # Sauvegarde du modèle
        mlflow.pytorch.log_model(model, "model")
\end{lstlisting}

\newpage

\section{Orchestration avec Airflow}

\subsection{DAG Airflow}

Le DAG (Directed Acyclic Graph) définit le workflow d'entraînement :

\begin{lstlisting}[language=Python]
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

with DAG(
    'pneumonia_pipeline',
    start_date=datetime(2025, 1, 1),
    schedule_interval=None,
    catchup=False,
    tags=['mlops', 'pneumonia'],
) as dag:
    
    start = PythonOperator(
        task_id='start_pipeline',
        python_callable=start_pipeline,
    )
    
    load_data = PythonOperator(
        task_id='load_data',
        python_callable=load_data_func,
    )
    
    train_model = PythonOperator(
        task_id='train_model',
        python_callable=train,
        op_kwargs={
            'data_dir': '/opt/airflow/dags/data/chest_xray',
            'epochs': 10,
            'batch_size': 64,
        },
    )
    
    validate_model = PythonOperator(
        task_id='validate_model',
        python_callable=validate,
    )
    
    # Définition des dépendances
    start >> load_data >> train_model >> validate_model
\end{lstlisting}

\subsection{Accès à Airflow}

\begin{itemize}
    \item \textbf{URL} : http://localhost:8080
    \item \textbf{Login} : airflow
    \item \textbf{Password} : airflow
\end{itemize}

\newpage

\section{Tracking avec MLflow}

\subsection{Configuration MLflow}

MLflow tracke automatiquement :
\begin{itemize}
    \item Hyperparamètres (epochs, batch\_size, learning\_rate)
    \item Métriques (accuracy, loss, precision, recall, F1)
    \item Modèles entraînés
    \item Artifacts (graphiques, fichiers)
\end{itemize}

\subsection{Accès à MLflow}

\begin{itemize}
    \item \textbf{URL} : http://localhost:5000
    \item Interface web pour visualiser toutes les expériences
    \item Comparaison des runs
    \item Téléchargement des modèles
\end{itemize}

\subsection{Exemple de Tracking}

\begin{lstlisting}[language=Python]
import mlflow

# Démarrer un run
with mlflow.start_run():
    # Log des paramètres
    mlflow.log_param("model", "ResNet18")
    mlflow.log_param("optimizer", "Adam")
    
    # Log des métriques
    mlflow.log_metric("accuracy", 0.85)
    mlflow.log_metric("precision", 0.83)
    mlflow.log_metric("recall", 0.87)
    
    # Log du modèle
    mlflow.pytorch.log_model(model, "model")
\end{lstlisting}

\newpage

\section{Versioning}

\subsection{Versioning du Code avec Git}

\begin{lstlisting}[language=bash]
# Initialiser Git
git init

# Ajouter les fichiers
git add .

# Commit
git commit -m "Initial commit"

# Push vers remote
git push origin main
\end{lstlisting}

\subsection{Versioning des Données avec DVC}

\begin{lstlisting}[language=bash]
# Initialiser DVC
dvc init

# Tracker le dataset
dvc add data/chest_xray

# Commit le fichier .dvc
git add data/chest_xray.dvc .gitignore
git commit -m "Add dataset with DVC"

# Configurer le remote storage
dvc remote add -d myremote /path/to/storage

# Push les données
dvc push
\end{lstlisting}

\subsection{Avantages du Versioning}

\begin{tcolorbox}[colback=green!5!white,colframe=green!75!black,title=Reproductibilité]
\begin{itemize}
    \item \textbf{Code versionné} : Historique complet des modifications
    \item \textbf{Données versionnées} : Même dataset pour tous
    \item \textbf{Environnement isolé} : Docker garantit la reproductibilité
    \item \textbf{Expériences trackées} : MLflow enregistre tout
\end{itemize}
\end{tcolorbox}

\newpage

\section{Interface Web Django}

\subsection{Architecture Django}

\textbf{Structure du projet :}

\begin{lstlisting}
django_app/
├── manage.py
├── pneumonia_detector/
│   ├── settings.py
│   ├── urls.py
│   └── wsgi.py
└── detector/
    ├── views.py
    ├── urls.py
    ├── forms.py
    └── templates/
        ├── base.html
        ├── index.html
        ├── upload.html
        └── result.html
\end{lstlisting}

\subsection{Fonctionnalités}

\begin{enumerate}
    \item \textbf{Page d'accueil} : Présentation du projet
    \item \textbf{Upload d'image} : Interface pour uploader une radiographie
    \item \textbf{Prédiction} : Affichage du résultat (NORMAL/PNEUMONIA)
    \item \textbf{Probabilités} : Visualisation des scores de confiance
\end{enumerate}

\subsection{Exemple de Vue Django}

\begin{lstlisting}[language=Python]
from django.shortcuts import render
from .forms import ImageUploadForm

def upload(request):
    if request.method == 'POST':
        form = ImageUploadForm(request.POST, request.FILES)
        if form.is_valid():
            # Sauvegarder l'image
            image = request.FILES['image']
            
            # Faire la prédiction
            result = predict(image)
            
            return render(request, 'result.html', {
                'prediction': result['prediction'],
                'confidence': result['confidence'],
            })
    else:
        form = ImageUploadForm()
    
    return render(request, 'upload.html', {'form': form})
\end{lstlisting}

\newpage

\section{Déploiement sur Heroku}

\subsection{Configuration Heroku}

\textbf{Fichiers nécessaires :}

\begin{enumerate}
    \item \textbf{Procfile} : Configuration du serveur
    \begin{lstlisting}
web: gunicorn pneumonia_detector.wsgi --log-file -
    \end{lstlisting}
    
    \item \textbf{runtime.txt} : Version Python
    \begin{lstlisting}
python-3.10.12
    \end{lstlisting}
    
    \item \textbf{requirements.txt} : Dépendances
    \begin{lstlisting}
Django==4.2.0
Pillow==10.0.0
gunicorn==21.2.0
whitenoise==6.6.0
    \end{lstlisting}
\end{enumerate}

\subsection{Commandes de Déploiement}

\begin{lstlisting}[language=bash]
# Login Heroku
heroku login

# Créer l'application
heroku create pneumonia-yassine

# Déployer
git push heroku master

# Migrer la base de données
heroku run python manage.py migrate

# Ouvrir l'application
heroku open
\end{lstlisting}

\subsection{URL de Production}

\textbf{Application déployée} : \url{https://pneumonia-yassine.herokuapp.com}

\newpage

\section{Résultats et Performance}

\subsection{Métriques du Modèle}

\begin{table}[h]
\centering
\begin{tabular}{|l|r|}
\hline
\textbf{Métrique} & \textbf{Valeur} \\
\hline
Test Accuracy & 85\% \\
Precision & 83\% \\
Recall & 87\% \\
F1 Score & 85\% \\
\hline
\end{tabular}
\caption{Performance du modèle (subset 10\%, 1 epoch)}
\end{table}

\textbf{Note} : Ces résultats sont obtenus avec 10\% du dataset et 1 epoch pour une démo rapide. En production avec 100\% des données et 20 epochs, l'accuracy peut atteindre 90\%+.

\subsection{Performance Opérationnelle}

\begin{itemize}
    \item \textbf{Temps d'entraînement} : 2-3 minutes (10\% data, 1 epoch)
    \item \textbf{Temps de prédiction} : < 1 seconde
    \item \textbf{Ressources} : Optimisé pour 8GB RAM
    \item \textbf{Scalabilité} : Docker permet le scaling horizontal
\end{itemize}

\newpage

\section{Guide d'Utilisation}

\subsection{Démarrage du Projet}

\begin{enumerate}
    \item \textbf{Cloner le repository}
    \begin{lstlisting}[language=bash]
git clone <repository-url>
cd PROJET_MLOPS
    \end{lstlisting}
    
    \item \textbf{Démarrer l'infrastructure}
    \begin{lstlisting}[language=bash]
docker-compose up -d
    \end{lstlisting}
    
    \item \textbf{Accéder aux interfaces}
    \begin{itemize}
        \item Airflow : \url{http://localhost:8080}
        \item MLflow : \url{http://localhost:5000}
        \item Django : \url{http://localhost:8000}
    \end{itemize}
\end{enumerate}

\subsection{Lancer un Entraînement}

\textbf{Via Airflow UI :}
\begin{enumerate}
    \item Ouvrir \url{http://localhost:8080}
    \item Chercher le DAG \texttt{pneumonia\_pipeline}
    \item Cliquer sur le bouton "Trigger DAG"
    \item Suivre l'exécution en temps réel
\end{enumerate}

\textbf{Via CLI :}
\begin{lstlisting}[language=bash]
docker-compose exec airflow-scheduler \
    airflow dags trigger pneumonia_pipeline
\end{lstlisting}

\subsection{Visualiser les Résultats}

\begin{enumerate}
    \item Ouvrir MLflow : \url{http://localhost:5000}
    \item Cliquer sur l'experiment "pneumonia\_detection"
    \item Comparer les différents runs
    \item Télécharger le meilleur modèle
\end{enumerate}

\newpage

\section{Troubleshooting}

\subsection{Problèmes Courants}

\subsubsection{Docker Build Lent}

\textbf{Problème} : Le build Docker prend plus de 20 minutes

\textbf{Solution} : Utiliser PyTorch CPU-only
\begin{lstlisting}[language=bash]
# Dans requirements.txt
torch==2.1.2+cpu
torchvision==0.16.2+cpu
\end{lstlisting}

\subsubsection{DataLoader Errors}

\textbf{Problème} : Erreurs de shared memory avec DataLoader

\textbf{Solution} : Mettre \texttt{num\_workers=0}
\begin{lstlisting}[language=Python]
train_loader = DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=True,
    num_workers=0  # Important pour Docker
)
\end{lstlisting}

\subsubsection{MLflow Permissions}

\textbf{Problème} : Erreurs de permissions MLflow

\textbf{Solution} : Ajouter \texttt{user: root} dans docker-compose.yaml
\begin{lstlisting}[language=yaml]
mlflow:
  image: ghcr.io/mlflow/mlflow:v2.9.2
  user: root  # Ajouter cette ligne
  ports:
    - "5000:5000"
\end{lstlisting}

\newpage

\section{Améliorations Futures}

\subsection{Court Terme}

\begin{itemize}
    \item Entraînement avec 100\% des données
    \item Optimisation des hyperparamètres (Grid Search, Bayesian Optimization)
    \item Ajout de métriques avancées (courbes ROC, matrices de confusion)
    \item Alertes Slack/Email pour les runs
    \item Monitoring avancé avec Prometheus/Grafana
\end{itemize}

\subsection{Long Terme}

\begin{itemize}
    \item API REST avec Django REST Framework
    \item Authentification multi-utilisateurs
    \item Dashboard de visualisation temps réel
    \item Auto-ML pour optimisation automatique
    \item Migration vers AWS/GCP/Azure
    \item CI/CD avec GitHub Actions
    \item Tests automatisés (unit tests, integration tests)
\end{itemize}

\newpage

\section{Conclusion}

\subsection{Réalisations}

Ce projet démontre la création d'un \textbf{pipeline MLOps complet et professionnel} pour la détection de pneumonie :

\begin{itemize}
    \item ✅ Infrastructure robuste avec Docker
    \item ✅ Orchestration automatisée avec Airflow
    \item ✅ Tracking complet avec MLflow
    \item ✅ Versioning du code (Git) et des données (DVC)
    \item ✅ Modèle performant avec PyTorch
    \item ✅ Interface web moderne avec Django
    \item ✅ Déploiement cloud sur Heroku
    \item ✅ Documentation exhaustive
\end{itemize}

\subsection{Compétences Démontrées}

\textbf{Techniques :}
\begin{itemize}
    \item Machine Learning (PyTorch, Transfer Learning)
    \item MLOps (Airflow, MLflow, DVC)
    \item DevOps (Docker, Git, CI/CD)
    \item Web Development (Django, HTML/CSS)
    \item Cloud (Heroku)
\end{itemize}

\textbf{Soft Skills :}
\begin{itemize}
    \item Résolution de problèmes complexes
    \item Architecture système
    \item Documentation technique
    \item Gestion de projet
\end{itemize}

\subsection{Impact}

Ce projet peut avoir un impact réel dans le domaine médical :
\begin{itemize}
    \item Diagnostic plus rapide de la pneumonie
    \item Réduction de la charge de travail des radiologues
    \item Amélioration de l'accès aux soins dans les zones sous-équipées
    \item Système scalable et déployable en production
\end{itemize}

\newpage

\section*{Annexes}

\subsection*{A. Commandes Utiles}

\textbf{Docker :}
\begin{lstlisting}[language=bash]
# Démarrer
docker-compose up -d

# Arrêter
docker-compose down

# Voir les logs
docker-compose logs -f airflow-scheduler

# Nettoyer
docker-compose down -v
docker system prune -f
\end{lstlisting}

\textbf{Git :}
\begin{lstlisting}[language=bash]
# Status
git status

# Add
git add .

# Commit
git commit -m "message"

# Push
git push origin main
\end{lstlisting}

\textbf{DVC :}
\begin{lstlisting}[language=bash]
# Pull data
dvc pull

# Add data
dvc add data/chest_xray

# Push data
dvc push
\end{lstlisting}

\subsection*{B. Liens Utiles}

\begin{itemize}
    \item Airflow : \url{https://airflow.apache.org/}
    \item MLflow : \url{https://mlflow.org/}
    \item PyTorch : \url{https://pytorch.org/}
    \item Django : \url{https://www.djangoproject.com/}
    \item DVC : \url{https://dvc.org/}
    \item Heroku : \url{https://www.heroku.com/}
\end{itemize}

\end{document}
