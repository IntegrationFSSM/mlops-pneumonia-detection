# üîß Solution Alternative - Tester le Pipeline Manuellement

Si le DAG n'appara√Æt pas dans l'interface Airflow, vous pouvez quand m√™me **tester le pipeline manuellement** !

## ‚úÖ Option 1 : Ex√©cuter l'Entra√Ænement Directement

Vous pouvez lancer l'entra√Ænement directement sans passer par Airflow :

```powershell
# Se connecter au conteneur
docker-compose exec airflow-scheduler bash

# Lancer l'entra√Ænement
cd /opt/airflow/dags
python -c "from train_model import train; train()"
```

Cela va :
- ‚úÖ Entra√Æner le mod√®le ResNet18
- ‚úÖ Logger toutes les m√©triques dans MLflow
- ‚úÖ Sauvegarder le mod√®le

Ensuite, consultez les r√©sultats sur **http://localhost:5000** (MLflow).

---

## ‚úÖ Option 2 : D√©clencher le DAG en Ligne de Commande

M√™me si le DAG n'appara√Æt pas dans l'UI, vous pouvez le d√©clencher via CLI :

```powershell
# D√©clencher le DAG
docker-compose exec airflow-scheduler airflow dags trigger pneumonia_detection_pipeline

# Voir le statut
docker-compose exec airflow-scheduler airflow dags list-runs -d pneumonia_detection_pipeline
```

---

## ‚úÖ Option 3 : Forcer le Rafra√Æchissement d'Airflow

```powershell
# 1. Res√©rialiser tous les DAGs
docker-compose exec airflow-scheduler airflow dags reserialize

# 2. Red√©marrer les services
docker-compose restart airflow-scheduler airflow-webserver

# 3. Attendre 30 secondes
Start-Sleep -Seconds 30

# 4. Rafra√Æchir la page Airflow
```

---

## üêõ Probl√®me Connu : Volumes Docker sur Windows

Le probl√®me que vous rencontrez est **courant sur Windows** avec Docker Desktop. Les volumes ne se synchronisent pas toujours correctement.

### Solution Permanente

Modifiez `docker-compose.yaml` pour utiliser un volume nomm√© au lieu d'un bind mount :

```yaml
services:
  airflow-scheduler:
    volumes:
      - dags-volume:/opt/airflow/dags  # Au lieu de ./dags:/opt/airflow/dags
```

Puis copiez les fichiers manuellement :
```powershell
docker-compose cp dags/pipeline.py airflow-scheduler:/opt/airflow/dags/
docker-compose cp dags/train_model.py airflow-scheduler:/opt/airflow/dags/
```

---

## üìä V√©rifier que Tout Fonctionne

### 1. V√©rifier MLflow

Ouvrez **http://localhost:5000** - Vous devriez voir l'interface MLflow.

### 2. V√©rifier que le DAG existe

```powershell
docker-compose exec airflow-scheduler python -c "from pipeline import dag; print(dag)"
```

Si cela affiche `<DAG: pneumonia_detection_pipeline>`, le DAG est bien charg√© !

### 3. Lancer un Test Rapide

```powershell
# Test rapide avec 1 epoch
docker-compose exec airflow-scheduler python -c "from train_model import train; train(epochs=1)"
```

Cela prendra ~2-3 minutes et vous verrez les r√©sultats dans MLflow.

---

## üéØ Recommandation

**Pour l'instant, utilisez l'Option 1** (ex√©cution manuelle) pour tester que tout fonctionne.

Une fois que vous aurez vu les r√©sultats dans MLflow, nous pourrons r√©soudre le probl√®me d'affichage du DAG dans Airflow.

**L'important est que le pipeline fonctionne, m√™me si l'interface Airflow a un probl√®me d'affichage !** üòä
