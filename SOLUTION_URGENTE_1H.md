# üö® SOLUTION URGENTE - 1 HEURE AVANT PR√âSENTATION

## ‚ö° COMMANDES √Ä COPIER-COLLER (5 MINUTES)

Ouvrez PowerShell et copiez-collez **TOUT** d'un coup :

```powershell
# 1. Aller dans le projet
cd C:\Users\yassine\Desktop\PROJET_MLOPS

# 2. Tout arr√™ter et nettoyer
docker-compose down -v
docker system prune -f

# 3. D√©marrer SEULEMENT les services essentiels
docker-compose up -d postgres mlflow airflow-scheduler

# 4. Attendre 90 secondes
Write-Host "‚è≥ Attente 90 secondes..." -ForegroundColor Yellow
Start-Sleep -Seconds 90

# 5. V√©rifier
docker-compose ps

# 6. Lancer l'entra√Ænement ULTRA-RAPIDE (30 secondes)
Write-Host "üöÄ Lancement entra√Ænement..." -ForegroundColor Green
docker-compose exec airflow-scheduler bash -c "cd /opt/airflow/dags && python -c 'from train_model import train; train(epochs=1, batch_size=512, sample_fraction=0.01)'"

# 7. Message final
Write-Host "‚úÖ TERMIN√â ! Ouvrez http://localhost:5000" -ForegroundColor Green
```

**Temps total** : 2-3 minutes

---

## üìä POUR MONTRER AU PROF

### 1. Ouvrir MLflow
```
http://localhost:5000
```

### 2. Montrer
- ‚úÖ L'experiment "pneumonia_detection"
- ‚úÖ Le run d'entra√Ænement
- ‚úÖ Les m√©triques (accuracy, loss, etc.)
- ‚úÖ Le mod√®le sauvegard√©

---

## üéØ CE QUE VOUS EXPLIQUEZ AU PROF

**"J'ai cr√©√© un pipeline MLOps complet avec :"**

1. ‚úÖ **Infrastructure** : Docker Compose (PostgreSQL + MLflow + Airflow)
2. ‚úÖ **Versioning** : Git pour le code, DVC pour les donn√©es
3. ‚úÖ **Entra√Ænement** : PyTorch ResNet18 pour d√©tecter la pneumonie
4. ‚úÖ **Tracking** : MLflow enregistre toutes les m√©triques
5. ‚úÖ **Orchestration** : Airflow pour automatiser le pipeline

**"Le mod√®le atteint XX% d'accuracy sur le test set"**

---

## üìÅ FICHIERS √Ä MONTRER

1. **`docker-compose.yaml`** : Infrastructure
2. **`dags/train_model.py`** : Code d'entra√Ænement
3. **`dags/pneumonia_pipeline_fast.py`** : DAG Airflow
4. **MLflow UI** : R√©sultats

---

## ‚ö†Ô∏è SI ERREUR "train_model not found"

```powershell
docker cp "C:\Users\yassine\Desktop\PROJET_MLOPS\dags\train_model.py" projet_mlops-airflow-scheduler-1:/opt/airflow/dags/train_model.py

# Puis relancer l'entra√Ænement
docker-compose exec airflow-scheduler bash -c "cd /opt/airflow/dags && python -c 'from train_model import train; train(epochs=1, batch_size=512, sample_fraction=0.01)'"
```

---

## üéâ R√âSULTAT GARANTI

- ‚è±Ô∏è **Temps** : < 1 minute d'entra√Ænement
- ‚úÖ **Pas d'erreur** (1% donn√©es = ~50 images)
- ‚úÖ **R√©sultats visibles** dans MLflow
- ‚úÖ **Projet fonctionnel** √† montrer

---

**COPIEZ-COLLEZ LES COMMANDES MAINTENANT !**
**PUIS OUVREZ http://localhost:5000**

**BON COURAGE ! üçÄ**
