"""
Continuous Retraining Pipeline with Airflow, DVC, GitHub
DAG pour rÃ©entraÃ®nement automatique pÃ©riodique
"""

from airflow import DAG
from airflow.operators.python import PythonOperator, BranchPythonOperator
from airflow.operators.bash import BashOperator
from datetime import datetime, timedelta
import mlflow
import os

# Configuration
default_args = {
    'owner': 'yassine',
    'depends_on_past': False,
    'start_date': datetime(2025, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

def check_new_data(**context):
    """VÃ©rifie s'il y a de nouvelles donnÃ©es"""
    # Simuler la dÃ©tection de nouvelles donnÃ©es
    # En production: vÃ©rifier DVC, S3, ou autre source
    print("ðŸ” VÃ©rification de nouvelles donnÃ©es...")
    
    # Pour la dÃ©mo, on retourne toujours True
    # En production: comparer avec la derniÃ¨re version DVC
    has_new_data = True
    
    if has_new_data:
        print("âœ… Nouvelles donnÃ©es dÃ©tectÃ©es!")
        return 'pull_new_data'
    else:
        print("â„¹ï¸ Pas de nouvelles donnÃ©es")
        return 'skip_training'

def pull_new_data(**context):
    """Pull les nouvelles donnÃ©es avec DVC"""
    print("ðŸ“¥ Pulling nouvelles donnÃ©es avec DVC...")
    # En production: dvc pull
    print("âœ… DonnÃ©es mises Ã  jour!")

def train_new_model(**context):
    """EntraÃ®ne un nouveau modÃ¨le"""
    from train_model import train
    
    print("ðŸš€ DÃ©marrage de l'entraÃ®nement du nouveau modÃ¨le...")
    
    # EntraÃ®ner avec les nouvelles donnÃ©es
    train(
        data_dir='/opt/airflow/dags/data/chest_xray',
        epochs=1,  # Augmenter en production
        batch_size=64,
        sample_fraction=0.1,  # Augmenter en production
    )
    
    print("âœ… Nouveau modÃ¨le entraÃ®nÃ©!")

def compare_models(**context):
    """Compare le nouveau modÃ¨le avec l'ancien"""
    print("ðŸ“Š Comparaison des modÃ¨les...")
    
    mlflow.set_tracking_uri("http://mlflow:5000")
    client = mlflow.tracking.MlflowClient()
    
    # RÃ©cupÃ©rer les 2 derniers runs
    experiment = client.get_experiment_by_name("pneumonia_detection")
    if experiment:
        runs = client.search_runs(
            experiment_ids=[experiment.experiment_id],
            order_by=["start_time DESC"],
            max_results=2
        )
        
        if len(runs) >= 2:
            new_run = runs[0]
            old_run = runs[1]
            
            new_accuracy = new_run.data.metrics.get('test_accuracy', 0)
            old_accuracy = old_run.data.metrics.get('test_accuracy', 0)
            
            print(f"ðŸ“ˆ Ancien modÃ¨le: {old_accuracy:.2%}")
            print(f"ðŸ“ˆ Nouveau modÃ¨le: {new_accuracy:.2%}")
            
            # DÃ©cider si on dÃ©ploie
            if new_accuracy > old_accuracy:
                print("âœ… Nouveau modÃ¨le meilleur! DÃ©ploiement...")
                return 'deploy_new_model'
            else:
                print("âš ï¸ Ancien modÃ¨le meilleur. Pas de dÃ©ploiement.")
                return 'keep_old_model'
    
    # Par dÃ©faut, dÃ©ployer
    return 'deploy_new_model'

def deploy_new_model(**context):
    """DÃ©ploie le nouveau modÃ¨le"""
    print("ðŸš€ DÃ©ploiement du nouveau modÃ¨le...")
    
    # En production:
    # 1. Sauvegarder le modÃ¨le dans un registry
    # 2. Mettre Ã  jour l'API Django
    # 3. RedÃ©ployer sur Heroku
    # 4. Notifier l'Ã©quipe
    
    print("âœ… Nouveau modÃ¨le dÃ©ployÃ© en production!")

def keep_old_model(**context):
    """Garde l'ancien modÃ¨le"""
    print("â„¹ï¸ Conservation de l'ancien modÃ¨le")

def send_notification(**context):
    """Envoie une notification de fin"""
    print("ðŸ“§ Notification: Pipeline de continuous retraining terminÃ©!")
    # En production: envoyer email/Slack

# DÃ©finition du DAG
with DAG(
    'continuous_retraining_pipeline',
    default_args=default_args,
    description='Pipeline de rÃ©entraÃ®nement continu automatique',
    schedule_interval='@daily',  # Tous les jours
    catchup=False,
    tags=['mlops', 'continuous-training', 'pneumonia'],
) as dag:
    
    # 1. VÃ©rifier s'il y a de nouvelles donnÃ©es
    check_data = BranchPythonOperator(
        task_id='check_new_data',
        python_callable=check_new_data,
        provide_context=True,
    )
    
    # 2. Pull les nouvelles donnÃ©es
    pull_data = PythonOperator(
        task_id='pull_new_data',
        python_callable=pull_new_data,
        provide_context=True,
    )
    
    # 3. EntraÃ®ner le nouveau modÃ¨le
    train = PythonOperator(
        task_id='train_new_model',
        python_callable=train_new_model,
        provide_context=True,
    )
    
    # 4. Comparer les modÃ¨les
    compare = BranchPythonOperator(
        task_id='compare_models',
        python_callable=compare_models,
        provide_context=True,
    )
    
    # 5a. DÃ©ployer le nouveau modÃ¨le
    deploy = PythonOperator(
        task_id='deploy_new_model',
        python_callable=deploy_new_model,
        provide_context=True,
    )
    
    # 5b. Garder l'ancien modÃ¨le
    keep_old = PythonOperator(
        task_id='keep_old_model',
        python_callable=keep_old_model,
        provide_context=True,
    )
    
    # 6. Skip training si pas de nouvelles donnÃ©es
    skip = BashOperator(
        task_id='skip_training',
        bash_command='echo "Pas de nouvelles donnÃ©es, skip training"',
    )
    
    # 7. Notification finale
    notify = PythonOperator(
        task_id='send_notification',
        python_callable=send_notification,
        provide_context=True,
        trigger_rule='none_failed_min_one_success',
    )
    
    # DÃ©finition du workflow
    check_data >> [pull_data, skip]
    pull_data >> train >> compare
    compare >> [deploy, keep_old]
    [deploy, keep_old, skip] >> notify
