"""
Script d'entra√Ænement pour la d√©tection de pneumonie sur radiographies thoraciques
Utilise PyTorch avec ResNet18 et MLflow pour le tracking
"""

import os
import mlflow
import mlflow.pytorch
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import numpy as np
from datetime import datetime


def get_data_loaders(data_dir, batch_size=32, sample_fraction=1.0):
    """
    Pr√©pare les DataLoaders pour l'entra√Ænement et la validation
    
    Args:
        data_dir: Chemin vers les donn√©es
        batch_size: Taille des batches
        sample_fraction: Fraction du dataset √† utiliser (0.1 = 10%, 1.0 = 100%)
    """
    # Transformations pour l'entra√Ænement (avec augmentation)
    train_transforms = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # Transformations pour la validation (sans augmentation)
    val_transforms = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # Chargement des datasets
    train_dataset = datasets.ImageFolder(
        root=os.path.join(data_dir, 'train'),
        transform=train_transforms
    )
    
    val_dataset = datasets.ImageFolder(
        root=os.path.join(data_dir, 'val'),
        transform=val_transforms
    )
    
    test_dataset = datasets.ImageFolder(
        root=os.path.join(data_dir, 'test'),
        transform=val_transforms
    )
    
    # √âchantillonner si sample_fraction < 1.0
    if sample_fraction < 1.0:
        import random
        
        # Train subset
        train_size = int(len(train_dataset) * sample_fraction)
        train_indices = random.sample(range(len(train_dataset)), train_size)
        train_dataset = torch.utils.data.Subset(train_dataset, train_indices)
        
        # Val subset
        val_size = int(len(val_dataset) * sample_fraction)
        val_indices = random.sample(range(len(val_dataset)), val_size)
        val_dataset = torch.utils.data.Subset(val_dataset, val_indices)
        
        # Test subset
        test_size = int(len(test_dataset) * sample_fraction)
        test_indices = random.sample(range(len(test_dataset)), test_size)
        test_dataset = torch.utils.data.Subset(test_dataset, test_indices)
    
    # Cr√©ation des DataLoaders (num_workers=0 pour √©viter les probl√®mes de shared memory dans Docker)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    
    return train_loader, val_loader, test_loader, ['NORMAL', 'PNEUMONIA']


def create_model(num_classes=2):
    """
    Cr√©e un mod√®le ResNet18 pr√©-entra√Æn√© et adapt√© pour la classification binaire
    """
    model = models.resnet18(pretrained=True)
    
    # Geler les couches pr√©-entra√Æn√©es (optionnel)
    for param in model.parameters():
        param.requires_grad = False
    
    # Remplacer la derni√®re couche pour notre t√¢che
    num_features = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Linear(num_features, 512),
        nn.ReLU(),
        nn.Dropout(0.3),
        nn.Linear(512, num_classes)
    )
    
    return model


def train_epoch(model, train_loader, criterion, optimizer, device):
    """
    Entra√Æne le mod√®le pour une epoch
    """
    model.train()
    running_loss = 0.0
    all_preds = []
    all_labels = []
    
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item() * inputs.size(0)
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())
    
    epoch_loss = running_loss / len(train_loader.dataset)
    epoch_acc = accuracy_score(all_labels, all_preds)
    
    return epoch_loss, epoch_acc


def validate(model, val_loader, criterion, device):
    """
    √âvalue le mod√®le sur l'ensemble de validation
    """
    model.eval()
    running_loss = 0.0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    epoch_loss = running_loss / len(val_loader.dataset)
    epoch_acc = accuracy_score(all_labels, all_preds)
    epoch_precision = precision_score(all_labels, all_preds, average='binary')
    epoch_recall = recall_score(all_labels, all_preds, average='binary')
    epoch_f1 = f1_score(all_labels, all_preds, average='binary')
    
    return epoch_loss, epoch_acc, epoch_precision, epoch_recall, epoch_f1


def train(data_dir='/opt/airflow/dags/data/chest_xray', 
          epochs=1,  # Chang√© √† 1 pour d√©mo rapide
          batch_size=64,  # Augment√© pour plus de vitesse
          learning_rate=0.001,
          sample_fraction=1.0):  # NOUVEAU: fraction du dataset √† utiliser
    """
    Fonction principale d'entra√Ænement avec tracking MLflow
    
    Args:
        data_dir: Chemin vers les donn√©es
        epochs: Nombre d'epochs
        batch_size: Taille des batches
        learning_rate: Taux d'apprentissage
        sample_fraction: Fraction du dataset (0.1 = 10%, 1.0 = 100%)
    """
    print("üöÄ D√©marrage de l'entra√Ænement...")
    
    # Configuration MLflow
    mlflow.set_tracking_uri("http://mlflow:5000")
    mlflow.set_experiment("pneumonia_detection")
    
    # D√©tection du device (GPU si disponible)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üì± Device utilis√©: {device}")
    
    with mlflow.start_run(run_name=f"resnet18_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):
        
        # Log des hyperparam√®tres
        mlflow.log_param("model_architecture", "ResNet18")
        mlflow.log_param("epochs", epochs)
        mlflow.log_param("batch_size", batch_size)
        mlflow.log_param("learning_rate", learning_rate)
        mlflow.log_param("optimizer", "Adam")
        mlflow.log_param("device", str(device))
        mlflow.log_param("sample_fraction", sample_fraction)  # NOUVEAU
        
        # Chargement des donn√©es
        print("üìä Chargement des donn√©es...")
        train_loader, val_loader, test_loader, classes = get_data_loaders(
            data_dir, batch_size, sample_fraction  # NOUVEAU param√®tre
        )
        print(f"   Classes: {classes}")
        print(f"   Train samples: {len(train_loader.dataset)}")
        print(f"   Val samples: {len(val_loader.dataset)}")
        print(f"   Test samples: {len(test_loader.dataset)}")
        
        # Cr√©ation du mod√®le
        print("üß† Cr√©ation du mod√®le...")
        model = create_model(num_classes=len(classes))
        model = model.to(device)
        
        # D√©finition de la loss et de l'optimizer
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        
        # Entra√Ænement
        print(f"\nüèãÔ∏è Entra√Ænement sur {epochs} epochs...")
        best_val_acc = 0.0
        
        for epoch in range(epochs):
            print(f"\n--- Epoch {epoch+1}/{epochs} ---")
            
            # Entra√Ænement
            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)
            print(f"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}")
            
            # Validation
            val_loss, val_acc, val_precision, val_recall, val_f1 = validate(model, val_loader, criterion, device)
            print(f"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}")
            
            # Log des m√©triques dans MLflow
            mlflow.log_metric("train_loss", train_loss, step=epoch)
            mlflow.log_metric("train_accuracy", train_acc, step=epoch)
            mlflow.log_metric("val_loss", val_loss, step=epoch)
            mlflow.log_metric("val_accuracy", val_acc, step=epoch)
            mlflow.log_metric("val_precision", val_precision, step=epoch)
            mlflow.log_metric("val_recall", val_recall, step=epoch)
            mlflow.log_metric("val_f1", val_f1, step=epoch)
            
            # Sauvegarde du meilleur mod√®le
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                mlflow.log_metric("best_val_accuracy", best_val_acc)
        
        # Test final
        print("\nüß™ √âvaluation sur le test set...")
        test_loss, test_acc, test_precision, test_recall, test_f1 = validate(model, test_loader, criterion, device)
        print(f"Test - Loss: {test_loss:.4f}, Acc: {test_acc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}")
        
        mlflow.log_metric("test_loss", test_loss)
        mlflow.log_metric("test_accuracy", test_acc)
        mlflow.log_metric("test_precision", test_precision)
        mlflow.log_metric("test_recall", test_recall)
        mlflow.log_metric("test_f1", test_f1)
        
        # Sauvegarde du mod√®le dans MLflow
        print("\nüíæ Sauvegarde du mod√®le dans MLflow...")
        mlflow.pytorch.log_model(model, "model")
        
        # Sauvegarde locale du mod√®le
        model_path = "/opt/airflow/dags/pneumonia_model.pth"
        torch.save(model.state_dict(), model_path)
        mlflow.log_artifact(model_path)
        
        print(f"\n‚úÖ Entra√Ænement termin√©!")
        print(f"   Meilleure accuracy validation: {best_val_acc:.4f}")
        print(f"   Test accuracy: {test_acc:.4f}")
        
        return {
            'best_val_acc': best_val_acc,
            'test_acc': test_acc,
            'test_precision': test_precision,
            'test_recall': test_recall,
            'test_f1': test_f1
        }


if __name__ == "__main__":
    # Pour tester localement
    results = train()
    print(f"\nüìà R√©sultats finaux: {results}")
